# -*- coding: utf-8 -*-
"""london.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JY3YVv-W0chP4T1c1_Cd45T8aTpK9MuQ
"""

import pandas
import numpy
import networkx as nx
import sklearn
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
from sklearn import model_selection
from sklearn import naive_bayes
from sklearn import neighbors
from sklearn import tree



"""DESCRIPCIÓN: Los datos son sobre co-delincuencia en una pandilla callejera del centro de la ciudad con sede en Londres, 2005-2009, que opera desde una urbanización social. Los datos provienen de datos anónimos de arrestos y condenas policiales de los miembros "confirmados" de la pandilla.

FORMATO DE DATOS: UCINET, .csv

DATOS: Matriz 1-Modal 54 x 54 personas por personas, no dirigido, valorado.

Valores de enlace de red:
                = 1 (pasar el rato juntos)
                = 2 (co-delinquen juntos)
                = 3 (cometer delitos juntos, delito grave)
                = 4 (co-delinquen juntos, delito grave, parientes)

Atributos: Edad, Lugar de nacimiento (1 = África Occidental, 2 = Caribe, 3 = Reino Unido, 4 = África Oriental), Residencia, Arrestos, Condenas, Prisión, Música.

!cd por ejemplo para que no lo reconozca como pyton
"""

data = pandas.read_csv("LONDON_GANG.csv",header=None,skiprows=1)
#borramos la primera fila y columna
data = data.iloc[: , 1:]
#printeamos las 5 primeras filas
print(data.head())
#dibujamos un grafo dirigido para calcular los grados con el comando in_degree y out_degree
grafo = nx.Graph(data.values)
nx.draw(grafo)

dataAttr = pandas.read_csv("LONDON_GANG_ATTR.csv",header=None,names=["Age","Birthplace","Residence","Arrests","Convictions","Prison","Music","Ranking"],skiprows=1)

print(dataAttr.head(5))

d = nx.coloring.greedy_color(grafo)
lColoring=sorted(d.items())
coloring = []
for e in lColoring:
  coloring.append(e[1])
print(coloring)

valencia = grafo.degree
print(valencia)

centrality = nx.degree_centrality(grafo)
print(centrality)

clust = nx.clustering(grafo)
print(clust)

grado=[ j for _,j in valencia()]
print(grado)

gCentrality=[ a for a in centrality.values()]
print(gCentrality)

gClustering=[ a for a in clust.values()]
print(gClustering)

londonatt= pandas.read_csv("LONDON_GANG_ATTR.csv",header=None,names=["Age","Birthplace","Residence","Arrests","Convictions","Prison","Music","Ranking"],skiprows=1)
londonatt2= pandas.read_csv("LONDON_GANG_ATTR.csv",header=None,names=["Age","Birthplace","Residence","Arrests","Convictions","Prison","Music","Ranking"],skiprows=1)
londonatt3= pandas.read_csv("LONDON_GANG_ATTR.csv",header=None,names=["Age","Birthplace","Residence","Arrests","Convictions","Prison","Music","Ranking"],skiprows=1)
londonatt4= pandas.read_csv("LONDON_GANG_ATTR.csv",header=None,names=["Age","Birthplace","Residence","Arrests","Convictions","Prison","Music","Ranking"],skiprows=1)
dataAtt2 = pandas.DataFrame(londonatt2)
dataAtt2["Centrality"] = gCentrality
dataAtt3 = pandas.DataFrame(londonatt3)
dataAtt3["Clustering"] = gClustering
dataAtt4 = pandas.DataFrame(londonatt4)
dataAtt4["Coloreado"] = coloring


dataAtt = pandas.DataFrame(londonatt)
dataAtt["grado"] = grado
dataAtt["Centrality"] = gCentrality
dataAtt["Clustering"] = gClustering
dataAtt["Coloreado"] = coloring
dataAtt4.head()

#Aquí empieza con el modelo relaciones

dataAttChanged = dataAtt[["Age","Birthplace","Residence","Arrests","Convictions","Music","Ranking","grado","Centrality","Clustering","Coloreado"]]
dataAttChanged2 = dataAtt2[["Age","Birthplace","Residence","Arrests","Convictions","Music","Ranking","Centrality"]]
dataAttChanged3 = dataAtt3[["Age","Birthplace","Residence","Arrests","Convictions","Music","Ranking","Clustering"]]
dataAttChanged4 = dataAtt4[["Age","Birthplace","Residence","Arrests","Convictions","Music","Ranking","Coloreado"]]
atributosRelacionales = dataAttChanged.loc[:, "Age":"Coloreado"]
objetivo = dataAtt["Prison"]
atributosRelacionales.head(5)

atributos = dataAttChanged.loc[:, "Age":"Ranking"]
atributos_grado = dataAttChanged.loc[:, "Age":"grado"]
atributos_centrality =  dataAttChanged2.loc[:, "Age":"Centrality"]
atributos_clustering =  dataAttChanged3.loc[:, "Age":"Clustering"]
atributos_coloreado =  dataAttChanged4.loc[:, "Age":"Coloreado"]

atributos_clustering.head(5)

objetivo.head(5)

print(pandas.Series(objetivo).value_counts(normalize=False))

"""Modelo de entrenamiento"""

#modelo de entrenamiento para los atributos normales
(atributos_entrenamiento, atributos_prueba, objetivo_entrenamiento, objetivo_prueba)= model_selection.train_test_split(atributos,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

#modelo de entrenamiento para los atributos relacionales
(atributos_entrenamiento_relacional, atributos_prueba_relacional, objetivo_entrenamiento_relacional, objetivo_prueba_relacional)= model_selection.train_test_split(atributosRelacionales,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

(atributos_entrenamiento_grado, atributos_prueba_grado, objetivo_entrenamiento_grado, objetivo_prueba_grado)= model_selection.train_test_split(atributos_grado,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

(atributos_entrenamiento_centrality, atributos_prueba_centrality, objetivo_entrenamiento_centrality, objetivo_prueba_centrality)= model_selection.train_test_split(atributos_centrality,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

(atributos_entrenamiento_clustering, atributos_prueba_clustering, objetivo_entrenamiento_clustering, objetivo_prueba_clustering)= model_selection.train_test_split(atributos_clustering,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

(atributos_entrenamiento_coloreado, atributos_prueba_coloreado, objetivo_entrenamiento_coloreado, objetivo_prueba_coloreado)= model_selection.train_test_split(atributos_coloreado,objetivo,random_state=3333,test_size=.33,stratify=objetivo)

print("MODELO DE ATRIBUTOS POR DEFECTO")
print("prueba")
print("ejemplos Necesarios:", 54 * .33)
print("filas de array:", atributos_prueba.shape[0])
print("longitud objetivo de prueba", len(objetivo_prueba))
print("entrenamiento")
print("ejemplos Necesarios:", 54 * .67)
print("filas de array:", atributos_entrenamiento.shape[0])
print("longitud objetivo de prueba", len(objetivo_entrenamiento))

print("MODELO DE ATRIBUTOS POR DEFECTO Y RELACIONALES")
print("prueba")
print("ejemplos Necesarios:", 54 * .33)
print("filas de array:", atributos_prueba_relacional.shape[0])
print("longitud objetivo de prueba", len(objetivo_prueba_relacional))
print("entrenamiento")
print("ejemplos Necesarios:", 54 * .67)
print("filas de array:", atributos_entrenamiento_relacional.shape[0])
print("longitud objetivo de prueba", len(objetivo_entrenamiento_relacional))

"""Naive Bayes

"""

#last chance
codificador_atributos = preprocessing.OrdinalEncoder()
atributos_codificados = codificador_atributos.fit_transform(atributos)

codificador_objetivo = preprocessing.LabelEncoder()
objetivo_codificado = codificador_objetivo.fit_transform(objetivo)

(atributos_entrenamiento_cod, atributos_prueba_cod,
 objetivo_entrenamiento_cod, objetivo_prueba_cod) = model_selection.train_test_split(
    
    atributos_codificados, objetivo_codificado,
    random_state=3333,
    test_size=.33,
    stratify=objetivo_codificado)

#alpha = hiperparametro de suavizado
naivbayes = naive_bayes.CategoricalNB(alpha=1.0)
naivbayes.fit(atributos_entrenamiento, objetivo_entrenamiento)

sc=naivbayes.score(atributos_prueba,objetivo_prueba)
print("la puntuación de naive bayes sobre los atributos de prueba y entrenamiento es :",sc)

"""Los datos recopilados anteriormente nos proporcionan la puntuación de el modelo naive bayes sobre el conjunto de prueba sin introducir los atributos propios del grafo. """

#Naive Bayes Relacional
naivbayesRelacional = naive_bayes.CategoricalNB(alpha=1.0)
naivbayesRelacional.fit(atributos_entrenamiento_relacional , objetivo_entrenamiento_relacional)

#naivbayesRelacional.score(atributos_prueba_relacional,objetivo_prueba_relacional)

"""KNN

"""

#distancia de hamming
 for n in range(1,5):
  KNN= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN.fit(atributos_entrenamiento,objetivo_entrenamiento)
  scores = cross_val_score(KNN, X=atributos_entrenamiento, y=objetivo_entrenamiento, cv=10)
  media_score=0
  for i in scores:
    media_score+=i
  media_score/=scores.size
  print("Para los atributos originales la puntuación")
  if(n==1):
    print("con", n, "vecino es",media_score)
  else:
    print("con", n, "vecinos es",media_score)

#euclidean
for n in range(1,5):
  KNN= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN.fit(atributos_entrenamiento,objetivo_entrenamiento)
  scores = cross_val_score(KNN, X=atributos_entrenamiento, y=objetivo_entrenamiento, cv=10)
  media_score=0
  for i in scores:
    media_score+=i
  media_score/=scores.size
  print("Para los atributos originales la puntuación")
  if(n==1):
    print("con", n, "vecino es",media_score)
  else:
    print("con", n, "vecinos es",media_score)

nuevos_ejemplos = [[20,1,0,16,4,1,1],[20,2,0,16,7,0,2]]

distancias, vecinos = KNN.kneighbors(nuevos_ejemplos)

# Vecinos más cercanos y distancia a ellos del primer ejemplo nuevo
print("Primer ejemplo nuevo:", nuevos_ejemplos[0])
print("5 vecinos más cercanos:")
print(vecinos[0])
# Los números que nos da vecinos[0] representan el indice de las filas que mas se parecen a nuestros números en los atributos de entrenamiento
print("Distancias a esos vecinos (cantidad de atributos con valores distintos / cantidad total de atributos):")
print(distancias[0])

# Vecinos más cercanos y distancia a ellos del segundo ejemplo nuevo
print("Primer ejemplo nuevo:", nuevos_ejemplos[1])
print("5 vecinos más cercanos:")
print(vecinos[1])
# Los números que nos da vecinos[1] representan el indice de las filas que mas se parecen a nuestros números en los atributos de entrenamiento
print("Distancias a esos vecinos (cantidad de atributos con valores distintos / cantidad total de atributos):")
print(distancias[1])

KNN.score(atributos_prueba,objetivo_prueba)

"""A partir de aquí probaremos el Modelo knn con datos relacionales"""

#hamming
for n in range(1,5):
  #todos los attr
  KNN_relacional= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN_relacional.fit(atributos_entrenamiento_relacional,objetivo_entrenamiento_relacional)
  scores = cross_val_score(KNN_relacional, X=atributos_entrenamiento_relacional, y=objetivo_entrenamiento_relacional, cv=10)
  media_score=0
  #grado
  KNN_grado= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN_grado.fit(atributos_entrenamiento_grado,objetivo_entrenamiento_grado)
  scores_grado = cross_val_score(KNN_grado, X=atributos_entrenamiento_grado, y=objetivo_entrenamiento_grado, cv=10)
  media_score_grado=0
  #centralidad
  KNN_centralidad= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN_centralidad.fit(atributos_entrenamiento_centrality,objetivo_entrenamiento_centrality)
  scores_centralidad = cross_val_score(KNN_centralidad, X=atributos_entrenamiento_centrality, y=objetivo_entrenamiento_centrality, cv=10)
  media_score_centralidad=0
  #clustering
  KNN_clustering= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN_clustering.fit(atributos_entrenamiento_clustering,objetivo_entrenamiento_clustering)
  scores_clustering = cross_val_score(KNN_clustering, X=atributos_entrenamiento_clustering, y=objetivo_entrenamiento_clustering, cv=10)
  media_score_clustering=0
  #coloreado
  KNN_coloreado= neighbors.KNeighborsClassifier(n_neighbors=n,metric="hamming")
  KNN_coloreado.fit(atributos_entrenamiento_coloreado,objetivo_entrenamiento_coloreado)
  scores_coloreado = cross_val_score(KNN_coloreado, X=atributos_entrenamiento_coloreado, y=objetivo_entrenamiento_coloreado, cv=10)
  media_score_coloreado=0
  for i in scores:
    media_score+=i
  media_score/=scores.size
  #
  for i in scores_grado:
    media_score_grado+=i
  media_score_grado/=scores_grado.size
  #
  for i in scores_centralidad:
    media_score_centralidad+=i
  media_score_centralidad/=scores_centralidad.size
  #
  for i in scores_clustering:
    media_score_clustering+=i
  media_score_clustering/=scores_clustering.size
  #
  for i in scores_coloreado:
    media_score_coloreado+=i
  media_score_coloreado/=scores_coloreado.size
  if(n==1):
    print("=========================================================")
    print("media de la puntuación con", n, "vecino y distancia hamming:")
  else:
    print("=========================================================")
    print("media de la puntuación con", n, "vecinos y distancia hamming:")
  print("Para todos los atributos relacionales:",media_score)
  print("Para el atributo relacional grado: ",media_score_grado)
  print("Para el atributo relacional centralidad: ",media_score_centralidad)
  print("Para el atributo relacional clustering: ",media_score_clustering)
  print("Para el atributo relacional coloreado ",media_score_coloreado)

KNN_relacional.score(atributos_prueba_relacional,objetivo_prueba_relacional)

#euclidean
for n in range(1,5):
  #todos los attr
  KNN_relacional= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN_relacional.fit(atributos_entrenamiento_relacional,objetivo_entrenamiento_relacional)
  scores = cross_val_score(KNN_relacional, X=atributos_entrenamiento_relacional, y=objetivo_entrenamiento_relacional, cv=10)
  media_score=0
  #grado
  KNN_grado= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN_grado.fit(atributos_entrenamiento_grado,objetivo_entrenamiento_grado)
  scores_grado = cross_val_score(KNN_grado, X=atributos_entrenamiento_grado, y=objetivo_entrenamiento_grado, cv=10)
  media_score_grado=0
  #centralidad
  KNN_centralidad= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN_centralidad.fit(atributos_entrenamiento_centrality,objetivo_entrenamiento_centrality)
  scores_centralidad = cross_val_score(KNN_centralidad, X=atributos_entrenamiento_centrality, y=objetivo_entrenamiento_centrality, cv=10)
  media_score_centralidad=0
  #clustering
  KNN_clustering= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN_clustering.fit(atributos_entrenamiento_clustering,objetivo_entrenamiento_clustering)
  scores_clustering = cross_val_score(KNN_clustering, X=atributos_entrenamiento_clustering, y=objetivo_entrenamiento_clustering, cv=10)
  media_score_clustering=0
  #coloreado
  KNN_coloreado= neighbors.KNeighborsClassifier(n_neighbors=n,metric="euclidean")
  KNN_coloreado.fit(atributos_entrenamiento_coloreado,objetivo_entrenamiento_coloreado)
  scores_coloreado = cross_val_score(KNN_coloreado, X=atributos_entrenamiento_coloreado, y=objetivo_entrenamiento_coloreado, cv=10)
  media_score_coloreado=0
  for i in scores:
    media_score+=i
  media_score/=scores.size
  #
  for i in scores_grado:
    media_score_grado+=i
  media_score_grado/=scores_grado.size
  #
  for i in scores_centralidad:
    media_score_centralidad+=i
  media_score_centralidad/=scores_centralidad.size
  #
  for i in scores_clustering:
    media_score_clustering+=i
  media_score_clustering/=scores_clustering.size
  #
  for i in scores_coloreado:
    media_score_coloreado+=i
  media_score_coloreado/=scores_coloreado.size
  if(n==1):
    print("===========================================================")
    print("media de la puntuación con", n, "vecino y distancia euclídea:")
  else:
    print("===========================================================")
    print("media de la puntuación con", n, "vecinos y distancia euclídea:")
  print("Para todos los atributos relacionales:",media_score)
  print("Para el atributo relacional grado: ",media_score_grado)
  print("Para el atributo relacional centralidad: ",media_score_centralidad)
  print("Para el atributo relacional clustering: ",media_score_clustering)
  print("Para el atributo relacional coloreado ",media_score_coloreado)

KNN_relacional.score(atributos_prueba_relacional,objetivo_prueba_relacional)

"""# Árboles de decisión

Árboles de decisión
"""

clf = tree.DecisionTreeClassifier()
clf = clf.fit(atributos_entrenamiento , objetivo_entrenamiento)

scores = cross_val_score(clf, X=atributos_entrenamiento, y=objetivo_entrenamiento, cv=8)
for i in scores:
  media_score+=i
media_score/=scores.size
media_originales=media_score
print("la media de la puntuación mediante validación cruzada es",media_score)

clf.score(atributos_prueba,objetivo_prueba)

sklearn.tree.plot_tree(clf)

#hacemos esto debido a que no se aprecia bien el grafo
tree.export_graphviz(clf,out_file="london.dot", 
                     filled = True)

"""Árboles de decisión con los datos relacionales"""

clf_relacionales = tree.DecisionTreeClassifier()
clf_relacionales = clf_relacionales.fit(atributos_entrenamiento_relacional , objetivo_entrenamiento_relacional)

scores = cross_val_score(clf_relacionales, X=atributos_entrenamiento_relacional, y=objetivo_entrenamiento_relacional, cv=10)
for i in scores:
  media_score+=i
media_score/=scores.size
media_relacionales=media_score
print("la media de la puntuación mediante validación cruzada para los atributos relacionales es",media_score)

clf_relacionales.score(atributos_prueba_relacional,objetivo_prueba_relacional)

sklearn.tree.plot_tree(clf_relacionales)

#hacemos esto debido a que no se aprecia bien el grafo
tree.export_graphviz(clf,out_file="londonRelacionales.dot", 
                     filled = True)

clf_grado = tree.DecisionTreeClassifier()
clf_grado = clf_grado.fit(atributos_entrenamiento_grado , objetivo_entrenamiento_grado)
scores = cross_val_score(clf_grado, X=atributos_entrenamiento_grado, y=objetivo_entrenamiento_grado, cv=10)
for i in scores:
  media_score+=i
media_score/=scores.size
media_grado=media_score
print("la media de la puntuación mediante validación cruzada es",media_score)

clf_centralidad = tree.DecisionTreeClassifier()
clf_centralidad = clf_centralidad.fit(atributos_entrenamiento_centrality , objetivo_entrenamiento_centrality)
scores = cross_val_score(clf_centralidad, X=atributos_entrenamiento_centrality, y=objetivo_entrenamiento_centrality, cv=10)
for i in scores:
  media_score+=i
media_score/=scores.size
media_centralidad=media_score
print("la media de la puntuación mediante validación cruzada para los atributos relacionales es",media_score)

clf_clustering = tree.DecisionTreeClassifier()
clf_clustering = clf_clustering.fit(atributos_entrenamiento_clustering , objetivo_entrenamiento_clustering)
scores = cross_val_score(clf_relacionales, X=atributos_entrenamiento_clustering, y=objetivo_entrenamiento_clustering, cv=10)
for i in scores:
  media_score+=i
media_score/=scores.size
media_coloreado=media_score
print("la media de la puntuación mediante validación cruzada es",media_score)

clf_coloreado = tree.DecisionTreeClassifier()
clf_coloreado = clf_coloreado.fit(atributos_entrenamiento_coloreado , objetivo_entrenamiento_coloreado)
scores = cross_val_score(clf_coloreado, X=atributos_entrenamiento_coloreado, y=objetivo_entrenamiento_coloreado, cv=10)
for i in scores:
  media_score+=i
media_score/=scores.size
media_coloreado=media_score
print("la media de la puntuación mediante validación cruzada es",media_score)

print("la media de la puntuación es:")

print("Para los atributos originales ",media_originales)
print("Para los atributos relacionales ",media_relacionales)
print("Para el atributo relacional grado",media_score_grado)
print("Para el atributo relacional centralidad ",media_centralidad)
print("Para el atributo relacional clustering ",media_score_clustering)
print("Para el atributo relacional coloreado ",media_coloreado)